## Итоги
Провели достаточно большую работу с данными, от импорта до построения приложения!
### EDA
Провели базовый EDA и предобработку:
- Построили EDA-дашборды по исходным данным, рассмотрели базовые статистики - убедились в гомогенности выборок трейна и теста 
- Изучили данные на предмет наличия дублей и пропусков, проверили корректность признаков (типы, единицы измерения) - предобработали датасеты и устранили выявленные проблемы
- Построили визуализации и корреляции (от классической корреляции Пирсона но phik) - установили взаимосвязи некоторых признаков друг с другом, а также связи признаков с целевой переменной
### Модели
Построили несколько ML-моделей с разными параметрами на входе
- Лин. рег на вещественных признаках с дефолтными гиперпараметрами, c дефолтными и со стандартизованными признаками
- Lasso и ElasticNet на вещественных признаках, со стандартизацией признаков и подбором гиперпараметров при помощи GridSearchCV
- Ridge на всех признаках с подбором гиперпараметров, со стандартизацией вещ. признаков, OHE категориальных, и подбором гиперпараметров при помощи GridSearchCV
- Собственный вариант с Ridge с выделением доп. фичей на базе текущих, логарифмированием нескольких признаков и целевой переменной, а также выделением полиномиальных признаков
В процессе сравнивали модели при помощи R^2 и MSE. Больший прирост по R^2 и уменьшения MSE добились добавлением категориальных переменных. Лучшей оказалась последняя модель, применённые в ней методы дали наибольший прирост - сохранили её в пайплайн вместе с предобработкой для дальнейшего инференса.


Её итоговые метрики на тесте - r2_score=0.9456489854822409, MSE=31242515172.727623. То есть, модель достаточно хорошо объясняет дисперсию данных (значение метрики близко в 1). MSE не очень интерпретируемая метрика, но если взять корень (RMSE) - получим значение 176755,52374036, то есть "в среднем" наша модель отклоняется на такую величину условных единиц, что звучит неплохо. 

### Бизнес-метрики
Реализовали несколько бизнес-метрик:
- долю прогнозов, отличающихся от реальных цен на эти авто не более чем на 10% (в одну или другую сторону)
- долю успешных прогнозов с учетом асимметричности (кастомно задающейся), с недопрогнозом не более 10% по дефолту, перепрогнозом не более 20% по дефолту
Убедились, что последняя модель также лучше работает на бизнес-метриках

### Интерактивное приложение в Streamlit
На базе полученных данных построили [сервис](https://vkayumov-car-price-prediction.streamlit.app/):
- Реализовали интерактивный EDA-дашборд с фильтрами, в котором можно целиком взглянуть на тренировочные данные, сравнить на визуализациях трейн и тест.
- Модель, полученную этапом ранее, использовали как инференс в сервисе - можно загрузить собственный .csv-файл, и получить предсказания. Также можно загрузить тестовый датасет, чтобы проверить модель
- В сервисе также отражены веса полученной модели 

### Точки роста
Что не получилось и можно было бы сделать лучше, что я бы точно добавил в следующих итерациях
- Хотелось бы, чтобы логарифмирование было частью пайплайна, а не было реализованно отдельными функциями, как сейчас
- Также хотелось бы, чтобы можно было загружать не "чистый" датасет, а исходный - с неправильным форматом колонок, пропусками и проч.
- Можно подумать над визуалом - можно сделать график зависимостей 2 признаков с возможностью кастомно выбрать Ох и Оу
- Локально python 3.9 и одни версии библиотек, а в стримлите ниже 3.10 нет, и были проблемы с запуском - долго мучался, чтобы "завелось" не локально. Нужно обновиться :)
